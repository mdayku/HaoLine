# YOLO Quantization Demo - HaoLine

## Model: YOLOv8n (Roof Damage Detection)

**Training:** 20 epochs on roof_damage_combined_v3 dataset (6,068 train / 1,748 val / 431 test images)

---

## Quantization Results

| Precision | File Size | Reduction | Status |
|-----------|-----------|-----------|--------|
| **FP32** | 11.67 MB | baseline | ✅ Full support |
| **FP16** | 5.94 MB | **-49%** | ⚠️ Requires TensorRT for inference |
| **INT8** | 3.19 MB | **-73%** | ⚠️ Requires TensorRT for inference |

---

## FP32 Test Set Performance

| Metric | Value |
|--------|-------|
| **mAP@50** | 44.0% |
| **mAP@50-95** | 19.3% |
| **Precision** | 61.2% |
| **Recall** | 39.2% |
| **Inference (CPU)** | 51.5 ms |

---

## Key Insights

### Size Reduction
- **FP16** achieves ~50% size reduction with typically <1% accuracy loss
- **INT8** achieves ~73% size reduction, ideal for edge deployment
- Both require TensorRT or specialized runtime for inference

### Deployment Recommendations

| Target | Recommended Precision | Why |
|--------|----------------------|-----|
| **Cloud GPU** | FP16 | Best speed/accuracy tradeoff |
| **Edge GPU (Jetson)** | INT8 | Smallest size, TensorRT native |
| **CPU Only** | FP32 | Full compatibility |

---

## Files Generated

```
demo_outputs/yolo_quantization/
├── models/
│   ├── yolov8n_fp32.onnx  (11.67 MB)
│   ├── yolov8n_fp16.onnx  (5.94 MB)
│   └── yolov8n_int8.onnx  (3.19 MB)
├── eval_results/
│   └── eval_fp32.json
└── train/
    └── weights/best.pt
```

---

## Next Steps

For full FP16/INT8 inference benchmarking, see:
- **Epic 22**: TensorRT Engine Introspection
- **Epic 31**: Automated Quantization Service

---

*Generated by HaoLine v0.2.6*
