# Deploy to Hugging Face Spaces (Docker)
# Automatically syncs the Streamlit app to HF Spaces on push to main
#
# Setup required:
# 1. Create a Space at huggingface.co/new-space (SDK: Docker)
# 2. Add HF_TOKEN secret in GitHub repo settings (Settings > Secrets > Actions)
#    - Get token from huggingface.co/settings/tokens (write access required)
# 3. Update HF_SPACE_NAME below to match your Space

name: Deploy to HF Spaces

on:
  push:
    branches: [main]
    paths:
      - 'src/haoline/**'
      - 'pyproject.toml'
      - '.github/workflows/deploy-hf-spaces.yml'
  workflow_dispatch:  # Allow manual triggering

env:
  HF_SPACE_NAME: mdayku/haoline  # Change to your-username/your-space-name

jobs:
  deploy:
    name: Deploy to Hugging Face Spaces
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || (github.event_name == 'push' && github.ref == 'refs/heads/main')

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          lfs: true

      - name: Check if HF_TOKEN is set
        id: check_token
        run: |
          if [ -z "${{ secrets.HF_TOKEN }}" ]; then
            echo "HF_TOKEN not set, skipping deployment"
            echo "skip=true" >> $GITHUB_OUTPUT
          else
            echo "skip=false" >> $GITHUB_OUTPUT
          fi

      - name: Install huggingface_hub
        if: steps.check_token.outputs.skip != 'true'
        run: pip install huggingface_hub

      - name: Create Space files
        if: steps.check_token.outputs.skip != 'true'
        run: |
          mkdir -p hf_space

          # Create Dockerfile
          cat > hf_space/Dockerfile << 'EOF'
          FROM python:3.11-slim

          WORKDIR /app

          # Install system dependencies
          RUN apt-get update && apt-get install -y \
              build-essential \
              git \
              && rm -rf /var/lib/apt/lists/*

          # Install haoline with web extras
          RUN pip install --no-cache-dir haoline[web]>=0.2.3

          # Create app entry point
          COPY app.py .

          # Expose Streamlit port
          EXPOSE 7860

          # HF Spaces expects port 7860
          CMD ["streamlit", "run", "app.py", "--server.port=7860", "--server.address=0.0.0.0", "--server.headless=true"]
          EOF

          # Create app.py
          cat > hf_space/app.py << 'EOF'
          """
          HaoLine - Universal Model Inspector
          Deployed via GitHub Actions from https://github.com/mdayku/HaoLine
          """
          # Import the Streamlit app from haoline package
          from haoline.streamlit_app import *

          # The streamlit_app module sets up the page on import
          # No additional code needed - Streamlit runs the module
          EOF

          # Create README for the Space
          cat > hf_space/README.md << 'EOF'
          ---
          title: HaoLine
          emoji: ðŸ”¬
          colorFrom: emerald
          colorTo: cyan
          sdk: docker
          pinned: false
          license: mit
          app_port: 7860
          ---

          # HaoLine (çš“çº¿) - Universal Model Inspector

          **See what's really inside your neural networks.**

          ## Features

          - **Upload Models**: ONNX, PyTorch (.pt), SafeTensors
          - **Interactive Graph**: Zoomable D3.js visualization of your architecture
          - **Hardware Estimates**: Performance predictions for 50+ GPU profiles
          - **AI Summaries**: GPT-powered executive summaries (bring your own API key)
          - **Export**: PDF, HTML, JSON, Markdown reports

          ## Usage

          1. Upload a model file (or use the demo)
          2. Select target hardware
          3. Click "Analyze Model"
          4. Explore the interactive report

          ## Links

          - **GitHub**: [github.com/mdayku/HaoLine](https://github.com/mdayku/HaoLine)
          - **PyPI**: `pip install haoline`
          - **Docs**: [README](https://github.com/mdayku/HaoLine#readme)

          ## Run Locally

          ```bash
          pip install haoline[web]
          haoline-web
          ```

          ---

          *Built with Streamlit â€¢ Deployed on Hugging Face Spaces*
          EOF

          echo "Created HF Space files:"
          ls -la hf_space/

      - name: Push to Hugging Face Space
        if: steps.check_token.outputs.skip != 'true'
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          cd hf_space
          
          # Configure git for HF
          git init
          git config user.email "github-actions@github.com"
          git config user.name "GitHub Actions"
          
          # Add all files
          git add .
          git commit -m "Deploy from GitHub Actions - $(date -u +%Y-%m-%d_%H:%M:%S)"
          
          # Push to HF Space (using token auth)
          git push --force https://mdayku:${HF_TOKEN}@huggingface.co/spaces/${HF_SPACE_NAME} main

      - name: Deployment status
        if: steps.check_token.outputs.skip != 'true'
        run: |
          echo "âœ… Deployed to https://huggingface.co/spaces/${HF_SPACE_NAME}"
          echo ""
          echo "Note: Docker build may take 2-5 minutes"

      - name: Skipped deployment
        if: steps.check_token.outputs.skip == 'true'
        run: |
          echo "âš ï¸ Deployment skipped - HF_TOKEN secret not configured"
          echo ""
          echo "To enable auto-deploy:"
          echo "1. Create a Space at https://huggingface.co/new-space (SDK: Docker)"
          echo "2. Get a token from https://huggingface.co/settings/tokens"
          echo "3. Add HF_TOKEN secret in GitHub repo settings"
          echo "4. Update HF_SPACE_NAME in this workflow file"
